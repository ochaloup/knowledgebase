= Effective Java (chapter 7)

:icons: font

icon:bookmark[] https://www.amazon.com/Effective-Java-Joshua-Bloch-ebook/dp/B078H61SCH

icon:tags[] java, programming.language, tips

== Chapter 7: Lamda and Streams

Problem: How to make a function objects in Java?
         The functional interfaces, lamdas and method references
         were added to Java to help here. The stream API was added
         to add support of these to libraries.
         How to make best use of them?

=== Item 42: why to prefer lamdas over anynymous classes?

It's easier and more comprehensible to read them.

[source,java]
----
// obsolete aynoymous class instance
Collections.sort(words, new Comparator<String>() {
  public int compare(String s1, String s2) {
    return Integer.compare(s1.length(), s2.length());
  }
});

// lamda expression as function object
Collections.sort(words, (s1,s2) -> Integer.compare(s1.length(), s2.length()));
----

NOTE: `s1` uses type the Java language feature of type interference
      where the type is deduced by compiler from context.
      There are some corner cases where the type can't be deduced
      (it's even defined in spec some such cases) the the way is to cast it manually
      or in case use the anonymous class as "workaround".

Prefere use of lamda but do not use lamda for more then 3 lines of code inside of the lamda.
Otherwise the lamda is long and badly readable. For longer inner methods
use the _anyonymous class_ (lamda lacks the documentation and the data of parameters)
or a _method reference_ (item 43).

Few limitations for lamda:

* lamda lacks names and documentation (anonymous class could be better)
* `this` keyword refers for enclosing instance for lamda.
  In _anyonymous class_ the `this` referes to the anonymous class instance instead.
* nor lamda expression neiter anonymous class can be reliably serialized.
  If you need serialization of the expression use _private static nested class_ (link:./effective-java-04.adoc[(Item 24)]).


=== Item 43: why to prefer _method references_ to lamdas?

_Method references_ are usually shorter in code when used. When used with a good
name they are better comprehensible for reader as well.

[source,java]
----
// long hard to understand lamda
map.merge(key, 1, (count, incr) -> count + incr);
// NOTE: merge function - if mapping is already present in the map
// the method applies the merge function to the item; if not present the default value (1) ins inserted

// shorter and with better name method reference
map.merge(key, 1, Integer::sum);
----

In some cases the lamda is shorter and more readable like

[source,java]
----
// method reference in the same class
service.execute(GoshThisClassNameIsHumogous::action);
// vs. lamda
service.execute(() -> action());

// method reference for identity
service.execute(Function::identity));
// vs. lamda
service.execute(x -> x);
----

There are several "types" of the method references.
The static one and 4 that uses the function object somehow.

.Types of method references
|===
|Method reference type | Example | Lamda Equivalent

|Static
|`Integer::parseInt`
|`str -> Integer.parseInt(str)`

|Bound
|`Instant.now::isAfter()`
|`Instant then = Instant.now; t-> then.isAfter(t);`

|Unbound
|`String::toLowerCase`
|`str -> str.toLowerCase()`

|Class Constructor
|`TreeMap<K,V>::new`
|`() -> new Treemap<K,V>`

|Array Constructor
|`int[]::new`
|`len -> new int[len]`
|===


=== Item 44: Why to prefer standard functional interfaces to creating new ones?

The Java 8 offers multiple functional interfaces which should be favored
as they provides flexibility, better comprehensible when used usually
and you don't repeat what was already done.

.Basic types of the functional interfaces from `java.util.function`
|===
|Interface   |Function Signature   | Example

|UnaryOperator<T>
|T apply(T t)
|String::toLowerCase

|BinaryOperator<T>
|T apply(T t1, T t2)
|BigInteger::add

|Predicate<T>
|boolean test(T t)
|Collection::isEmpty

|Function<T,R>
|R apply(T t)
|Arrays:asList

|Supplier<T>
|T get()
|Instant::now

|Consumer<T>
|void accept(T t)
|System.out::println
|===

NOTE: There are different flavors of these basic types. But the alternatives
      may be (easily) derived.

NOTE: don't be tempted to use basic functional interfaces with boxed primitives
      instead of primitive functional interfaces. It works but performance consequences
      could be deadly.

Use the definition of own functional interfaces when it will be commonly used
and could benefit from a descriptive name, it has a strong contract associated with,
it would benefit from custom default methods.
E.g. good example is https://docs.oracle.com/javase/8/docs/api/java/util/Comparator.html[`Comparator`].
It has the same signature as https://docs.oracle.com/javase/8/docs/api/java/util/function/ToIntBiFunction.html[`ToIntBiFunction`].
But `Comparator` has its own very specific purpose, strong contract, descriptive name and a lot of default methods.
It would be pretty bad idea to use `Comparator` just for providing a generic method of two parameters returning the int.
`Comparator` is used when the purpose is to compare and the implementation consider the contract defined by the `Comparator`.

=== Item 45: When to use streams?

Stream API in Java 8 makes possible to do bulk operations over data, sequentially or in parallel.
`Stream` is an abstraction which represents finite or infinite data elements.
The `stream pipeline` represents multistage computation on these elements.
Common sources for the stream includes collections, arrays, files, regular expressions pattern matchers,
number generators, and others streams.

The stream pipeline consists of a _source_ of the stream, followed with zero or more
_intermediate operations_ and one(!) _terminal operation_.
Stream pipeline is computed lazily and the computation runs only when needed
(thus it's possible to work with infinite streams).
When there is defined no terminal operation then the pipeline is a silent no-op.

The API for the streams is _fluent_.

By default the stream is sequential. Make the operation executed in parallel
is as simple as invoking the `parallel` method on the stream.
(But it is seldom appropriate to do so.)

Stream should be use judiciously for being readable in the code.
Usually the best is to combine iterative approach with the functional stream style one.

[source,java]
----
// note: two words are anagrams if they consist of the same letters in a different order
// e.g. staple and petals are anagrams, if we alphabetize them (change the order of characters to be ordered by alphabet)
// both of them will be in form "aelpst"
public class Anagrams {
  // Overuse of streams
  public static void main(String[] args) throws IOException {
    File dictionary = new File(args[0]); // file where dictionary is loaded from
    // printing only group of words bigger than the arguments
    //   (ie. group of size 1 is all words to be printed)
    int minimumGroupSize = Integer.parseInt(args[1]);

    Map<String, Set<String>> groups = new HashMap<>();
    try (Stream<String> words = Files.lines(dictionary)) {
      words.collect(
        groupingBy(word -> word.chars().sorted().collect(
          StringBuilder::new,
          (sb,c) -> sb.append((char) c),
          StringBuilder::append).
            toString()))
        .values().stream()
          .filter(group -> group.size() >= minGroupSize)
          .map(group -> group.size() + ": " + group)
          .forEach(System.out::println);
    }
  }
}
----

Example of comparison of iterative approach of cartesian product and the stream-based one.
The example shows computation of deck of cards where on the input is an `Enum` of _Ranks_ and _Suits_.

[source,java]
----
// iterative
List<Card> newDeck() {
  List<Card> result = new ArrayList<>();
  for(Suit suit: Suit.values()) {
    for(Rank rank: Rank.values()) {
      result.add(new Card(suit,rank));
    }
  }
  return result;
}

// stream-based
List<Card> newDeck() {
  return Stream.of(Suit.values())
    .flatMap(suit -> Stream.of(Rank.values())
      .map(rank -> new Card(suit, rank)))
    .collect(toList());
}
----

=== Item 46: How to write a function in stream right?

The preference should be to use side-effect-free functions.
It's based of the fact how functional programming paradigm should be used.
When streams are used then its paradigm should be used.
There are reasons to use the iterative paradigm and sometimes is better
to use the stream one. But it's often matter of preference.

Let's see and example of stream API which is not used in the paradigm way.
It's iterative code masquerading as stream code.
All work is done in the terminal `forEach` operation, lamda mutates the external state.

[source,java]
----
Map<String,Long> freq = new HashMap<>();
try(Stream<String> words = new Scanner(file).tokens()) {
  words.forEach(word -> {
    freq.merge(word.toLowerCase(), 1L, Long::sum);
  })
}
----

The same task in stream paradigm way.
Here the `Collectors API` is used which collects the stream items into a collection.

[source,java]
----
Map<String,Long> freq = new HashMap<>();
try(Stream<String> words = new Scanner(file).tokens()) {
  freq = words.collect(groupingBy(String::toLowerCase, counting()));
}
----

NOTE: `forEach` should be used only to report the result of a stream computation,
      never to perform the computation

The `Collectors API` contains several types of collectors.

NOTE: it's wise to statically import all members of `Collectors`
      for making the stream more readable

* gathering stream into a true `Collection`: `toList()`, `toSet()`, `toCollection(collectionFactory)`
* simple collecting stream into a `Map`: `toMap(keyMapper, valueMapper)`
* complicated forms of `Map` collectors: `toMap(keyMapper, valueMapper, mergerFunction)` and `groupingBy` which defines
  a strategy to handle collision with a _merger function_ (as a third argument).
  The merge function is `BinaryOperator<V>` where `V` is `value` type of `Map`.
* specific `Map` implementation collector: `toMap(keyMapper, valueMapper, mergerFunction, mapFactory)`,
  e.g. map factor for creation of `EnumMap` or `TreeMap`
* collector that groups data into categories while returning a map `groupingBy(categoryFunction)`,
  by default returns _a `HashMap` of `List`, as an alternative there is a `groupingByConcurrent` where
  `ConcurrentHashMap` is used.
* to join a stream of `CharSequence` which is `joining` and is useful when working with `String`

=== Item 47: What return type to use when `Stream` was introduced in Java 8?

As each of us has a different customs for working with data then somebody wants to use
`Stream` and the other one `Iterable`. The trouble is that there is no easy way
to convert the `Stream` and `Iterable` and vice versa.

As utility methods we can create this

[source,java]
----
// Adapter from Stream<E> to Iterable<E>
// the `Stream` contains the iterator method but it has to be typed
//   (here the typying is implicit as it's known what type the method returns)
public static <E> Iterable<E> iterableOf(Stream<E> stream) {
  return stream::iterator;
}

// Adapter from Iterable<E> to Stream<E>
public static <E> Stream<E> streamOf(Iterable<E> iter) {
  return StreamSupport.stream(iterable.spliterator(), false);
}
----

But the best is probably to return `Collection`. It can be easily converted to `Stream`
with available method `Stream.of` (and from arrays to iterator with `Arrays.asList`).

NOTE: do not store a large sequence in memory just to return it as a collection

If there is need for some "infinite" number of elements then you can consider
to implement own custom `Collection`. If it's not feasible then return `Stream`
or `Iterable` which fits more natural.

NOTE: in future Java release maybe the `Stream` interface  will be adjusted
      to extend `Iterable`, if that happens then `Stream` could be returned
      preferably as it will allow both - stream processing and iteration.


=== Item 48: why to be cautious about parallel streams?

Parallelizing the stream processing is easy as to add `parallel()` call
to the processing pipeline. Java executes such in `fork-join` pool
and all processes shares the pool. Slow processing of one task which takes
a lot of resources may slow down other pipeplines as well.

On top of this the wrongly used `parallel()` could make issues. There could be
a live lock or deadlock when used without caring.
E.g. using `limit()` means that only number of items are taken to the output.
`Parallel()` then runs multiple actions and expecting to just thrown those
which will not fit the limit. But if we use some long calculation where the
next iteration takes much more than all previous ones (e.g. calculation of
  the next prime number takes more time than calculation of all previous ones)
then `parallel` means calculation of next 2 more which would be "limited"
but until calculated the pipeline has to wait. Here such pipeline with `parallel()`
will be slower than without it.

NOTE: parallelizing a pipeline is unlikely to increase its performance if the source
      is from `Stream.iterate`, or the intermediate operation `limit` is used

A good clue: performance gains from parallelism are best on streams over `ArrayList`,
`HashMap`, `HashSet`, and `ConcurentHashMap` instances; arrays; `int` ranges;
and `long` ranges.
They all can be cheaply split into sub-ranges of any desired sizes
(the stream library use for this task the `spliterator` which is returned
by `spliterator` method on `Stream` or `Iterable`).
For good paralellizing is necessary the datastructure to provide good-to-excellent _locality of reference_
when the subrange processed sequentially - which means the sequential references are stored
together in memory. This means the loading the memory to CPU cache is here for help.
Otherwise the threads spend much of their idle time on waiting for transfering data from memory
to processor's cache.

Important note: parellizing the stream is performance(!) optimalization
and it should be considered so.

A good place to use parallelism on the stream

[source,java]
----
// number of primes less than or equal to 'n'
static long pi(long n) {
  return LongStream.rangeClosed(2,n)
    .parallel()
    .mapToObj(BigInteger::valueOf)
    .filter(i -> i.isProbablePrime(50))
    .count();
}
----

TIP: if you are going to parallelize a stream of random numbers,
     start with `SplittableRandom` rather than a `ThreadLocalRandom`
